{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb0178f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/yizj/Desktop/HBN/pheno_assessment/data/raw'),\n",
       " PosixPath('/Users/yizj/Desktop/HBN/pheno_assessment/data/interim'),\n",
       " PosixPath('/Users/yizj/Desktop/HBN/pheno_assessment/data/synth'),\n",
       " PosixPath('/Users/yizj/Desktop/HBN/pheno_assessment/data/reports'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "ROOT = Path(\"/Users/yizj/Desktop/HBN/pheno_assessment\").resolve()\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\"\n",
    "INTERIM_DIR = ROOT / \"data\" / \"interim\"\n",
    "SYNTH_DIR = ROOT / \"data\" / \"synth\"\n",
    "REPORTS_DIR = ROOT / \"data\" / \"reports\"\n",
    "\n",
    "for d in [INTERIM_DIR, SYNTH_DIR, REPORTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_DIR, INTERIM_DIR, SYNTH_DIR, REPORTS_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52236861",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_TOKENS = {\"\", \"NULL\", \"null\", \"NaN\", \"nan\"}\n",
    "\n",
    "def load_hbn_assessment(path: Path, standardize_cols=True) -> pd.DataFrame:\n",
    "    # read all as strings first (stable)\n",
    "    df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "\n",
    "    if \"Identifiers\" not in df.columns:\n",
    "        raise ValueError(f\"{path.name}: expected column 'Identifiers' not found.\")\n",
    "\n",
    "    # drop template row(s): Identifiers like \",assessment\"\n",
    "    df = df[~df[\"Identifiers\"].str.startswith(\",\", na=False)].copy()\n",
    "\n",
    "    # split Identifiers -> subject_id,eventname\n",
    "    parts = df[\"Identifiers\"].str.split(\",\", n=1, expand=True)\n",
    "    df[\"subject_id\"] = parts[0].str.strip()\n",
    "    df[\"eventname\"]  = parts[1].str.strip()\n",
    "\n",
    "    # normalize missing tokens\n",
    "    df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
    "\n",
    "    # standardize header commas for code safety (optional)\n",
    "    if standardize_cols:\n",
    "        df.columns = [c.replace(\",\", \"_\") for c in df.columns]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8190f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericize(df: pd.DataFrame, cols):\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbddf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "META_HINTS = [\n",
    "    \"Administration\", \"Comment\", \"Data_entry\", \"Days_Baseline\", \"EID\", \"PSCID\",\n",
    "    \"START_DATE\", \"Season\", \"Site\", \"Study\", \"Visit_label\", \"Year\"\n",
    "]\n",
    "\n",
    "# Item patterns across instruments:\n",
    "# CBCL: CBCL_01, CBCL_113A, CBCLpre_100a, etc.\n",
    "# These are \"item-level\" (not aggregates).\n",
    "ITEM_PATTERNS = [\n",
    "    re.compile(r\".*_[0-9]+[A-Za-z]*$\"),          # ..._01, ..._113A\n",
    "    re.compile(r\".*_100[a-z]$\"),                 # ..._100a, ..._100b\n",
    "    re.compile(r\".*_(pre_)?[0-9]+[A-Za-z]*$\"),   # a bit more permissive for pre variants\n",
    "]\n",
    "\n",
    "def is_meta_col(col: str) -> bool:\n",
    "    return any(h in col for h in META_HINTS) or col in {\"Identifiers\", \"subject_id\", \"eventname\"}\n",
    "\n",
    "_item_index_re = re.compile(r\"^(?P<prefix>.+)_(?P<idx>\\d{1,3})(?P<suf>[A-Za-z]?)$\")\n",
    "\n",
    "def is_item_col(col: str, prefix: str) -> bool:\n",
    "    if not col.startswith(prefix + \"_\"):\n",
    "        return False\n",
    "    m = _item_index_re.match(col)\n",
    "    if not m:\n",
    "        return False\n",
    "    idx = int(m.group(\"idx\"))\n",
    "    # plausible item index range; adjust if needed\n",
    "    return 1 <= idx <= 250\n",
    "\n",
    "def get_aggregate_cols(df: pd.DataFrame, prefix: str):\n",
    "    \"\"\"\n",
    "    Aggregate columns = instrument-derived summary scores/subscales/etc.\n",
    "    Includes things like:\n",
    "      - NLES_P_TotalEvents, NLES_P_Aware, NLES_P_Upset_Total, ...\n",
    "      - SCARED_P_GD, SCARED_P_Total, ...\n",
    "      - CBCL_Pre_DSM_ADHP, CBCL_Pre_Total_T, CBCL_Pre_OP, ...\n",
    "    Excludes metadata and item-level responses.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        if is_meta_col(c):\n",
    "            continue\n",
    "        if not c.startswith(prefix + \"_\"):\n",
    "            continue\n",
    "        if is_item_col(c, prefix):\n",
    "            continue\n",
    "        cols.append(c)\n",
    "    return cols\n",
    "\n",
    "def extract_aggregates(df: pd.DataFrame, file_tag: str) -> pd.DataFrame:\n",
    "    prefix = infer_prefix_with_check(df)\n",
    "    agg_cols = get_aggregate_cols(df, prefix)\n",
    "\n",
    "    # numeric conversion only for aggregate cols\n",
    "    df_num = numericize(df, agg_cols)\n",
    "\n",
    "    out = df_num[[\"subject_id\", \"eventname\"]].copy()\n",
    "\n",
    "    for c in agg_cols:\n",
    "        out[f\"{file_tag}__{c}\"] = df_num[c]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d3b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def infer_prefix(df: pd.DataFrame) -> str:\n",
    "    admin_cols = [c for c in df.columns if c.endswith(\"_Administration\")]\n",
    "    if admin_cols:\n",
    "        return admin_cols[0].replace(\"_Administration\", \"\")\n",
    "\n",
    "    # fallback: most frequent prefix among non-meta columns\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        if c in {\"Identifiers\", \"subject_id\", \"eventname\"}:\n",
    "            continue\n",
    "        if is_meta_col(c):\n",
    "            continue\n",
    "        if \"_\" in c:\n",
    "            candidates.append(\"_\".join(c.split(\"_\")[:2]) if c.count(\"_\") >= 2 else c.split(\"_\")[0])\n",
    "    if candidates:\n",
    "        return Counter(candidates).most_common(1)[0][0]\n",
    "    return \"INSTR\"\n",
    "\n",
    "def infer_prefix_with_check(df):\n",
    "    prefix = infer_prefix(df)\n",
    "    agg = get_aggregate_cols(df, prefix)\n",
    "    if len(agg) == 0:\n",
    "        # fallback: try the most frequent 1-token prefix as well\n",
    "        one_tok = []\n",
    "        for c in df.columns:\n",
    "            if is_meta_col(c): \n",
    "                continue\n",
    "            if \"_\" in c:\n",
    "                one_tok.append(c.split(\"_\")[0])\n",
    "        if one_tok:\n",
    "            prefix2 = Counter(one_tok).most_common(1)[0][0]\n",
    "            agg2 = get_aggregate_cols(df, prefix2)\n",
    "            if len(agg2) > 0:\n",
    "                return prefix2\n",
    "    return prefix\n",
    "\n",
    "def sanity_keys(df, name=\"df\"):\n",
    "    assert \"subject_id\" in df.columns and \"eventname\" in df.columns, f\"{name}: missing keys\"\n",
    "    assert df[\"subject_id\"].notna().all(), f\"{name}: null subject_id\"\n",
    "    # eventname can be null if parsing fails; flag it:\n",
    "    if df[\"eventname\"].isna().mean() > 0:\n",
    "        print(f\"WARNING {name}: eventname missing rate = {df['eventname'].isna().mean():.3f}\")\n",
    "    dup = df.duplicated(subset=[\"subject_id\",\"eventname\"]).mean()\n",
    "    if dup > 0:\n",
    "        print(f\"WARNING {name}: duplicate key rate = {dup:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07bf214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdverseChildhoodExperiencesScale_child.csv (77, 26) prefix: ACE\n",
      "AdverseChildhoodExperiencesScale_parent.csv (2197, 33) prefix: ACE_P\n",
      "ChildBehaviorChecklist_parent.csv (4301, 161) prefix: CBCL\n",
      "ChildBehaviorChecklist_parentPreschool.csv (161, 146) prefix: CBCL_Pre\n",
      "ChildrensDepressionInventory_child.csv (175, 57) prefix: CDI_SR\n",
      "ChildrensDepressionInventory_parent.csv (210, 92) prefix: CDI_P\n",
      "ConnersADHDRatingScales.csv (3256, 66) prefix: C3SR\n",
      "ConnersAdultADHDRatingScales.csv (121, 51) prefix: CAARS\n",
      "NegativeLifeEventsScale_child.csv (1251, 85) prefix: NLES_SR\n",
      "NegativeLifeEventsScale_parent.csv (4148, 82) prefix: NLES_P\n",
      "ScreenForChildAnxietyRelatedDisorders_child.csv (3187, 62) prefix: SCARED_SR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n",
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScreenForChildAnxietyRelatedDisorders_parent.csv (4177, 151) prefix: CDI_P\n",
      "StateTraitAnxietyInventory.csv (73, 61) prefix: STAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/vsf2fnhd3bz458z2nvlnyrmm0000gn/T/ipykernel_14967/54876077.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({tok: np.nan for tok in MISSING_TOKENS})\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"AdverseChildhoodExperiencesScale_child.csv\",\n",
    "    \"AdverseChildhoodExperiencesScale_parent.csv\",\n",
    "    \"ChildBehaviorChecklist_parent.csv\",\n",
    "    \"ChildBehaviorChecklist_parentPreschool.csv\",\n",
    "    \"ChildrensDepressionInventory_child.csv\",\n",
    "    \"ChildrensDepressionInventory_parent.csv\",\n",
    "    \"ConnersADHDRatingScales.csv\",\n",
    "    \"ConnersAdultADHDRatingScales.csv\",\n",
    "    \"NegativeLifeEventsScale_child.csv\",\n",
    "    \"NegativeLifeEventsScale_parent.csv\",\n",
    "    \"ScreenForChildAnxietyRelatedDisorders_child.csv\",\n",
    "    \"ScreenForChildAnxietyRelatedDisorders_parent.csv\",\n",
    "    \"StateTraitAnxietyInventory.csv\",\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for fn in files:\n",
    "    p = RAW_DIR / fn\n",
    "    if not p.exists():\n",
    "        print(\"MISSING:\", fn)\n",
    "        continue\n",
    "    df = load_hbn_assessment(p, standardize_cols=True)\n",
    "    dfs[fn] = df\n",
    "    print(fn, df.shape, \"prefix:\", infer_prefix(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256b443f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CBCL_Pre',\n",
       " 29,\n",
       " ['CBCL_Pre_CBCLPre_AB',\n",
       "  'CBCL_Pre_CBCLPre_AB_T',\n",
       "  'CBCL_Pre_CBCLPre_AD',\n",
       "  'CBCL_Pre_CBCLPre_AD_T',\n",
       "  'CBCL_Pre_CBCLPre_AP',\n",
       "  'CBCL_Pre_CBCLPre_AP_T',\n",
       "  'CBCL_Pre_CBCLPre_DSM_ADHP',\n",
       "  'CBCL_Pre_CBCLPre_DSM_ADHP_T',\n",
       "  'CBCL_Pre_CBCLPre_DSM_AP',\n",
       "  'CBCL_Pre_CBCLPre_DSM_AP_T',\n",
       "  'CBCL_Pre_CBCLPre_DSM_AnxP',\n",
       "  'CBCL_Pre_CBCLPre_DSM_AnxP_T',\n",
       "  'CBCL_Pre_CBCLPre_DSM_ODP',\n",
       "  'CBCL_Pre_CBCLPre_DSM_ODP_T',\n",
       "  'CBCL_Pre_CBCLPre_DSM_PDP',\n",
       "  'CBCL_Pre_CBCLPre_DSM_PDP_T',\n",
       "  'CBCL_Pre_CBCLPre_Ext',\n",
       "  'CBCL_Pre_CBCLPre_Ext_T',\n",
       "  'CBCL_Pre_CBCLPre_Int',\n",
       "  'CBCL_Pre_CBCLPre_Int_T',\n",
       "  'CBCL_Pre_CBCLPre_OP',\n",
       "  'CBCL_Pre_CBCLPre_SC',\n",
       "  'CBCL_Pre_CBCLPre_SC_T',\n",
       "  'CBCL_Pre_CBCLPre_SP',\n",
       "  'CBCL_Pre_CBCLPre_SP_T',\n",
       "  'CBCL_Pre_CBCLPre_Total',\n",
       "  'CBCL_Pre_CBCLPre_Total_T',\n",
       "  'CBCL_Pre_CBCLPre_WD',\n",
       "  'CBCL_Pre_CBCLPre_WD_T'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs[\"ChildBehaviorChecklist_parentPreschool.csv\"]\n",
    "prefix = infer_prefix_with_check(df)\n",
    "agg_cols = get_aggregate_cols(df, prefix)\n",
    "prefix, len(agg_cols), agg_cols[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7eaa71",
   "metadata": {},
   "source": [
    " Extract per-instrument aggregate tables (in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a1f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdverseChildhoodExperiencesScale_child: (77, 3) | dup_key_rate=0.0000\n",
      "AdverseChildhoodExperiencesScale_parent: (2197, 3) | dup_key_rate=0.0000\n",
      "ChildBehaviorChecklist_parent: (4301, 26) | dup_key_rate=0.0000\n",
      "ChildBehaviorChecklist_parentPreschool: (161, 31) | dup_key_rate=0.0000\n",
      "ChildrensDepressionInventory_child: (175, 16) | dup_key_rate=0.0000\n",
      "ChildrensDepressionInventory_parent: (210, 8) | dup_key_rate=0.0000\n",
      "ConnersADHDRatingScales: (3256, 14) | dup_key_rate=0.0000\n",
      "ConnersAdultADHDRatingScales: (121, 12) | dup_key_rate=0.0000\n",
      "NegativeLifeEventsScale_child: (1251, 6) | dup_key_rate=0.0000\n",
      "NegativeLifeEventsScale_parent: (4148, 6) | dup_key_rate=0.0000\n",
      "ScreenForChildAnxietyRelatedDisorders_child: (3187, 8) | dup_key_rate=0.0000\n",
      "ScreenForChildAnxietyRelatedDisorders_parent: (4177, 8) | dup_key_rate=0.0000\n",
      "StateTraitAnxietyInventory: (73, 8) | dup_key_rate=0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>tag</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_cols</th>\n",
       "      <th>n_agg_cols</th>\n",
       "      <th>dup_key_rate</th>\n",
       "      <th>eventname_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChildBehaviorChecklist_parentPreschool.csv</td>\n",
       "      <td>ChildBehaviorChecklist_parentPreschool</td>\n",
       "      <td>161</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChildBehaviorChecklist_parent.csv</td>\n",
       "      <td>ChildBehaviorChecklist_parent</td>\n",
       "      <td>4301</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChildrensDepressionInventory_child.csv</td>\n",
       "      <td>ChildrensDepressionInventory_child</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ConnersADHDRatingScales.csv</td>\n",
       "      <td>ConnersADHDRatingScales</td>\n",
       "      <td>3256</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConnersAdultADHDRatingScales.csv</td>\n",
       "      <td>ConnersAdultADHDRatingScales</td>\n",
       "      <td>121</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChildrensDepressionInventory_parent.csv</td>\n",
       "      <td>ChildrensDepressionInventory_parent</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ScreenForChildAnxietyRelatedDisorders_child.csv</td>\n",
       "      <td>ScreenForChildAnxietyRelatedDisorders_child</td>\n",
       "      <td>3187</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ScreenForChildAnxietyRelatedDisorders_parent.csv</td>\n",
       "      <td>ScreenForChildAnxietyRelatedDisorders_parent</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>StateTraitAnxietyInventory.csv</td>\n",
       "      <td>StateTraitAnxietyInventory</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NegativeLifeEventsScale_child.csv</td>\n",
       "      <td>NegativeLifeEventsScale_child</td>\n",
       "      <td>1251</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NegativeLifeEventsScale_parent.csv</td>\n",
       "      <td>NegativeLifeEventsScale_parent</td>\n",
       "      <td>4148</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_child.csv</td>\n",
       "      <td>AdverseChildhoodExperiencesScale_child</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_parent.csv</td>\n",
       "      <td>AdverseChildhoodExperiencesScale_parent</td>\n",
       "      <td>2197</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "3         ChildBehaviorChecklist_parentPreschool.csv   \n",
       "2                  ChildBehaviorChecklist_parent.csv   \n",
       "4             ChildrensDepressionInventory_child.csv   \n",
       "6                        ConnersADHDRatingScales.csv   \n",
       "7                   ConnersAdultADHDRatingScales.csv   \n",
       "5            ChildrensDepressionInventory_parent.csv   \n",
       "10   ScreenForChildAnxietyRelatedDisorders_child.csv   \n",
       "11  ScreenForChildAnxietyRelatedDisorders_parent.csv   \n",
       "12                    StateTraitAnxietyInventory.csv   \n",
       "8                  NegativeLifeEventsScale_child.csv   \n",
       "9                 NegativeLifeEventsScale_parent.csv   \n",
       "0         AdverseChildhoodExperiencesScale_child.csv   \n",
       "1        AdverseChildhoodExperiencesScale_parent.csv   \n",
       "\n",
       "                                             tag  n_rows  n_cols  n_agg_cols  \\\n",
       "3         ChildBehaviorChecklist_parentPreschool     161      31          29   \n",
       "2                  ChildBehaviorChecklist_parent    4301      26          24   \n",
       "4             ChildrensDepressionInventory_child     175      16          14   \n",
       "6                        ConnersADHDRatingScales    3256      14          12   \n",
       "7                   ConnersAdultADHDRatingScales     121      12          10   \n",
       "5            ChildrensDepressionInventory_parent     210       8           6   \n",
       "10   ScreenForChildAnxietyRelatedDisorders_child    3187       8           6   \n",
       "11  ScreenForChildAnxietyRelatedDisorders_parent    4177       8           6   \n",
       "12                    StateTraitAnxietyInventory      73       8           6   \n",
       "8                  NegativeLifeEventsScale_child    1251       6           4   \n",
       "9                 NegativeLifeEventsScale_parent    4148       6           4   \n",
       "0         AdverseChildhoodExperiencesScale_child      77       3           1   \n",
       "1        AdverseChildhoodExperiencesScale_parent    2197       3           1   \n",
       "\n",
       "    dup_key_rate  eventname_unique  \n",
       "3            0.0                 1  \n",
       "2            0.0                 1  \n",
       "4            0.0                 1  \n",
       "6            0.0                 1  \n",
       "7            0.0                 1  \n",
       "5            0.0                 1  \n",
       "10           0.0                 1  \n",
       "11           0.0                 1  \n",
       "12           0.0                 1  \n",
       "8            0.0                 1  \n",
       "9            0.0                 1  \n",
       "0            0.0                 1  \n",
       "1            0.0                 1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_by_file = {}\n",
    "meta_rows = []\n",
    "\n",
    "for fn, df in dfs.items():\n",
    "    tag = Path(fn).stem  # e.g., ChildBehaviorChecklist_parent\n",
    "    agg = extract_aggregates(df, file_tag=tag)\n",
    "\n",
    "    # basic key sanity\n",
    "    sanity_keys(agg, name=tag)\n",
    "\n",
    "    # duplicate key rate\n",
    "    dup_rate = agg.duplicated(subset=[\"subject_id\", \"eventname\"]).mean()\n",
    "\n",
    "    meta_rows.append({\n",
    "        \"file\": fn,\n",
    "        \"tag\": tag,\n",
    "        \"n_rows\": len(agg),\n",
    "        \"n_cols\": agg.shape[1],\n",
    "        \"n_agg_cols\": agg.shape[1] - 2,\n",
    "        \"dup_key_rate\": dup_rate,\n",
    "        \"eventname_unique\": agg[\"eventname\"].nunique(dropna=True),\n",
    "    })\n",
    "\n",
    "    agg_by_file[fn] = agg\n",
    "    print(f\"{tag}: {agg.shape} | dup_key_rate={dup_rate:.4f}\")\n",
    "\n",
    "meta_df = pd.DataFrame(meta_rows).sort_values(\"n_agg_cols\", ascending=False)\n",
    "meta_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06dc0b8",
   "metadata": {},
   "source": [
    "Export REAL aggregate tables to data/interim/\n",
    "\n",
    "Each file becomes: data/interim/<instrument>_aggregates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bcd258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 13 aggregate tables to /Users/yizj/Desktop/HBN/pheno_assessment/data/interim\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>interim_path</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>2197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChildBehaviorChecklist_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>4301</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChildBehaviorChecklist_parentPreschool.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>161</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChildrensDepressionInventory_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChildrensDepressionInventory_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ConnersADHDRatingScales.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>3256</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConnersAdultADHDRatingScales.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>121</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NegativeLifeEventsScale_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>1251</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NegativeLifeEventsScale_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>4148</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file  \\\n",
       "0   AdverseChildhoodExperiencesScale_child.csv   \n",
       "1  AdverseChildhoodExperiencesScale_parent.csv   \n",
       "2            ChildBehaviorChecklist_parent.csv   \n",
       "3   ChildBehaviorChecklist_parentPreschool.csv   \n",
       "4       ChildrensDepressionInventory_child.csv   \n",
       "5      ChildrensDepressionInventory_parent.csv   \n",
       "6                  ConnersADHDRatingScales.csv   \n",
       "7             ConnersAdultADHDRatingScales.csv   \n",
       "8            NegativeLifeEventsScale_child.csv   \n",
       "9           NegativeLifeEventsScale_parent.csv   \n",
       "\n",
       "                                        interim_path  rows  cols  \n",
       "0  /Users/yizj/Desktop/HBN/pheno_assessment/data/...    77     3  \n",
       "1  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  2197     3  \n",
       "2  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  4301    26  \n",
       "3  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   161    31  \n",
       "4  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   175    16  \n",
       "5  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   210     8  \n",
       "6  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  3256    14  \n",
       "7  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   121    12  \n",
       "8  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  1251     6  \n",
       "9  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  4148     6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written = []\n",
    "\n",
    "for fn, agg in agg_by_file.items():\n",
    "    tag = Path(fn).stem\n",
    "    out_path = INTERIM_DIR / f\"{tag}_aggregates.csv\"\n",
    "    agg.to_csv(out_path, index=False)\n",
    "    written.append({\"file\": fn, \"interim_path\": str(out_path), \"rows\": len(agg), \"cols\": agg.shape[1]})\n",
    "\n",
    "written_df = pd.DataFrame(written)\n",
    "written_df.to_csv(REPORTS_DIR / \"interim_aggregate_exports.csv\", index=False)\n",
    "\n",
    "print(\"Wrote\", len(written_df), \"aggregate tables to\", INTERIM_DIR)\n",
    "written_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe3d6e",
   "metadata": {},
   "source": [
    "Synthetic per-instrument aggregates (same schema, safe IDs)\n",
    "\n",
    "This preserves marginal distributions and missingness patterns. It also keeps joinability across instruments optional; since you’re doing per-instrument, we’ll generate IDs per instrument (privacy-safe). If later you want cross-instrument joins, tell me and I’ll switch to a shared synthetic ID spine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f08ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 13 synthetic aggregate tables to /Users/yizj/Desktop/HBN/pheno_assessment/data/synth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>synth_path</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdverseChildhoodExperiencesScale_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>2197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChildBehaviorChecklist_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>4301</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChildBehaviorChecklist_parentPreschool.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>161</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChildrensDepressionInventory_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChildrensDepressionInventory_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ConnersADHDRatingScales.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>3256</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConnersAdultADHDRatingScales.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>121</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NegativeLifeEventsScale_child.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>1251</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NegativeLifeEventsScale_parent.csv</td>\n",
       "      <td>/Users/yizj/Desktop/HBN/pheno_assessment/data/...</td>\n",
       "      <td>4148</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file  \\\n",
       "0   AdverseChildhoodExperiencesScale_child.csv   \n",
       "1  AdverseChildhoodExperiencesScale_parent.csv   \n",
       "2            ChildBehaviorChecklist_parent.csv   \n",
       "3   ChildBehaviorChecklist_parentPreschool.csv   \n",
       "4       ChildrensDepressionInventory_child.csv   \n",
       "5      ChildrensDepressionInventory_parent.csv   \n",
       "6                  ConnersADHDRatingScales.csv   \n",
       "7             ConnersAdultADHDRatingScales.csv   \n",
       "8            NegativeLifeEventsScale_child.csv   \n",
       "9           NegativeLifeEventsScale_parent.csv   \n",
       "\n",
       "                                          synth_path  rows  cols  \n",
       "0  /Users/yizj/Desktop/HBN/pheno_assessment/data/...    77     3  \n",
       "1  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  2197     3  \n",
       "2  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  4301    26  \n",
       "3  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   161    31  \n",
       "4  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   175    16  \n",
       "5  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   210     8  \n",
       "6  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  3256    14  \n",
       "7  /Users/yizj/Desktop/HBN/pheno_assessment/data/...   121    12  \n",
       "8  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  1251     6  \n",
       "9  /Users/yizj/Desktop/HBN/pheno_assessment/data/...  4148     6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def synth_bootstrap_table(df: pd.DataFrame, seed: int = 0, id_prefix=\"SYN\"):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    syn = df.sample(n=len(df), replace=True, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # replace subject_id with synthetic ids\n",
    "    syn[\"subject_id\"] = [f\"{id_prefix}_{i:06d}\" for i in range(len(syn))]\n",
    "\n",
    "    return syn\n",
    "\n",
    "synth_by_file = {}\n",
    "written_synth = []\n",
    "\n",
    "for i, (fn, real_agg) in enumerate(agg_by_file.items()):\n",
    "    tag = Path(fn).stem\n",
    "    syn = synth_bootstrap_table(real_agg, seed=42 + i, id_prefix=f\"SYN_{tag[:10]}\")\n",
    "\n",
    "    # ensure schema match\n",
    "    assert list(syn.columns) == list(real_agg.columns), f\"Schema mismatch for {tag}\"\n",
    "\n",
    "    synth_by_file[fn] = syn\n",
    "\n",
    "    out_path = SYNTH_DIR / f\"{tag}_aggregates.csv\"\n",
    "    syn.to_csv(out_path, index=False)\n",
    "    written_synth.append({\"file\": fn, \"synth_path\": str(out_path), \"rows\": len(syn), \"cols\": syn.shape[1]})\n",
    "\n",
    "written_synth_df = pd.DataFrame(written_synth)\n",
    "written_synth_df.to_csv(REPORTS_DIR / \"synth_aggregate_exports.csv\", index=False)\n",
    "\n",
    "print(\"Wrote\", len(written_synth_df), \"synthetic aggregate tables to\", SYNTH_DIR)\n",
    "written_synth_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f07e1",
   "metadata": {},
   "source": [
    "Validation report: missingness + summary stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
